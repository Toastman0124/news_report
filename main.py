import os
import requests
import feedparser
from deep_translator import GoogleTranslator
import urllib.parse

# å¾ç’°å¢ƒè®Šæ•¸è®€å–æ¨é€ Key
SCKEY = os.environ.get("SCKEY")

def get_categorized_news(region_name, icon, lang_config, translate_to_chinese=False):
    """ä½¿ç”¨é—œéµå­—æœå°‹æ–¹å¼æŠ“å–åˆ†é¡æ–°è"""
    translator = GoogleTranslator(source='auto', target='zh-TW')
    region_content = f"## {icon} {region_name}\n"
    
    # åˆ†é¡èˆ‡å°æ‡‰æœå°‹é—œéµå­— (é‡å°ä¸åŒèªè¨€èª¿æ•´)
    categories = [
        ("æ”¿æ²»", "âš–ï¸", lang_config['politics']),
        ("ç¶“æ¿Ÿ", "ğŸ’°", lang_config['finance']),
        ("ç¤¾æœƒ", "ğŸ ", lang_config['society']),
        ("å¨›æ¨‚", "ğŸ­", lang_config['entertainment'])
    ]
    
    for cat_name, cat_icon, keyword in categories:
        try:
            # å°‡é—œéµå­—é€²è¡Œ URL ç·¨ç¢¼
            encoded_key = urllib.parse.quote(keyword)
            # ä½¿ç”¨ Google News æœå°‹ RSS ç¶²å€
            rss_url = f"https://news.google.com/rss/search?q={encoded_key}&hl={lang_config['hl']}&gl={lang_config['gl']}&ceid={lang_config['ceid']}"
            
            feed = feedparser.parse(rss_url)
            region_content += f"#### {cat_icon} {cat_name}\n"
            
            entries = feed.entries[:3]
            if not entries:
                region_content += "- (æš«ç„¡æ¶ˆæ¯)\n"
                continue
                
            for i, entry in enumerate(entries, 1):
                title = entry.title.rsplit(' - ', 1)[0]
                if translate_to_chinese:
                    try:
                        title = translator.translate(title)
                    except: pass
                
                region_content += f"{i}. {title} [ğŸ”—]({entry.link})\n"
            region_content += "\n"
        except:
            region_content += "- (è®€å–å¤±æ•—)\n"
            
    return region_content

def main():
    if not SCKEY:
        print("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° SCKEY")
        return

    # å„åœ‹èªè¨€èˆ‡æœå°‹é—œéµå­—é…ç½®
    configs = {
        "TW": {"hl": "zh-TW", "gl": "TW", "ceid": "TW:zh-Hant", 
               "politics": "æ”¿æ²»", "finance": "è²¡ç¶“", "society": "ç¤¾æœƒ", "entertainment": "å¨›æ¨‚"},
        "CN": {"hl": "zh-CN", "gl": "CN", "ceid": "CN:zh-Hans", 
               "politics": "æ”¿æ²»", "finance": "è²¡ç¶“", "society": "ç¤¾æœƒ", "entertainment": "å¨›æ¨‚"},
        "US": {"hl": "zh-TW", "gl": "US", "ceid": "US:zh-Hant", 
               "politics": "US Politics", "finance": "Economy", "society": "US News", "entertainment": "Entertainment"},
        "JP": {"hl": "ja", "gl": "JP", "ceid": "JP:ja", 
               "politics": "æ”¿æ²»", "finance": "çµŒæ¸ˆ", "society": "ç¤¾ä¼š", "entertainment": "ã‚¨ãƒ³ã‚¿ãƒ¡"},
        "KR": {"hl": "ko", "gl": "KR", "ceid": "KR:ko", 
               "politics": "ì •ì¹˜", "finance": "ê²½ì œ", "society": "ì‚¬íšŒ", "entertainment": "ì—°ì˜ˆ"}
    }

    report_body = "ğŸ“… ä»Šæ—¥äº”åœ°å„é¡æ–°èç²¾è¯ (12:00)\n\n"
    report_body += get_categorized_news("å°ç£", "ğŸ‡¹ğŸ‡¼", configs["TW"], False)
    report_body += get_categorized_news("ä¸­åœ‹å¤§é™¸", "ğŸ‡¨ğŸ‡³", configs["CN"], False)
    report_body += get_categorized_news("ç¾åœ‹ (åœ‹éš›)", "ğŸ‡ºğŸ‡¸", configs["US"], False)
    report_body += get_categorized_news("æ—¥æœ¬", "ğŸ‡¯ğŸ‡µ", configs["JP"], True)
    report_body += get_categorized_news("éŸ“åœ‹", "ğŸ‡°ğŸ‡·", configs["KR"], True)

    report_body += "---\nğŸ’¡ é»æ“Š [ğŸ”—] å³å¯é–±è®€è©³æƒ…ã€‚ç¥æ‚¨èˆ‡é•·è¼©èŠå¾—æ„‰å¿«ï¼"

    # æ¨é€è‡³å¾®ä¿¡
    push_url = f"https://sctapi.ftqq.com/{SCKEY}.send"
    requests.post(push_url, data={"title": "ğŸ“° äº”åœ°æ™‚äº‹åˆ†é¡å ± (å…± 60 å‰‡)", "desp": report_body})

if __name__ == "__main__":
    main()
